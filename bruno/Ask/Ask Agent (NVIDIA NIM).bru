meta {
  name: Ask Agent (NVIDIA NIM)
  type: http
  seq: 3
}

post {
  url: {{base_url}}/api/v1/stream
  body: json
  auth: none
}

headers {
  Content-Type: application/json
}

body:json {
  {
    "query": "What are the latest developments in large language models?",
    "provider": "nvidia_nim",
    "model": "nvidia_nim/openai/gpt-oss-120b",
    "top_k": 3,
    "temperature": 0.5,
    "max_iterations": 5,
    "timeout_seconds": 180,
    "session_id": "optional-uuid-for-conversation",
    "conversation_window": 5
  }
}

docs {
  Stream agent response with the NVIDIA NIM provider. Uses the gpt-oss-120b model
  (the system default) via LiteLLM prefix routing.

  ## Request Fields

  All fields except `query` are optional:

  | Field | Type | Default | Description |
  |-------|------|---------|-------------|
  | query | string | (required) | Question to ask the agent |
  | provider | string | null | LLM provider: "openai" or "nvidia_nim" |
  | model | string | null | Model in LiteLLM format (e.g. "nvidia_nim/openai/gpt-oss-120b") |
  | top_k | int | 3 | Number of chunks to retrieve (1-10) |
  | temperature | float | 0.3 | LLM temperature (0.0-1.0) |
  | max_iterations | int | 5 | Max agent loop iterations (1-20) |
  | timeout_seconds | int | null | Agent timeout in seconds (10-600, default from server config: 180) |
  | session_id | string | null | UUID for multi-turn conversation continuity |
  | conversation_window | int | 5 | Number of prior turns to include as context (1-10) |
  | guardrail_threshold | int | 75 | Minimum relevance score to pass guardrail (0-100) |
  | max_retrieval_attempts | int | 3 | Max retrieval-rewrite cycles (1-5) |

  ## Authentication

  Requires a valid Clerk JWT in the Authorization header.

  ## Tier Gating

  Free-tier users cannot customize provider, model, temperature, top_k,
  guardrail_threshold, max_retrieval_attempts, conversation_window, max_iterations,
  or timeout_seconds. These fields are silently reset to defaults. Upgrade to Pro
  for full parameter control.

  ## SSE Event Types

  Response streams as Server-Sent Events with these event types:
  STATUS, CONTENT, SOURCES, METADATA, CITATIONS, CONFIRM_INGEST,
  INGEST_COMPLETE, ERROR, DONE.
}
